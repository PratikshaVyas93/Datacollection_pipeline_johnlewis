# Datacollection_pipeline_johnlewis
This data collection pipeline project mainly focus on collecting/scraping data of https://www.johnlewis.com website. 
Using selenium module/library of python. 

All the actions and steps are taken to implement this project from scraping the website to uploading the data on aws cloud services,that all mentioned on this README.md file.

Technologies that are used in this project : Python and its modules (boto3, math, os, selenium, urllib, uuid, json).

From now onwards, the file describe each and every milestone of this project with detail descriptions.
## Milestone 1 - Decide the website that I am passionate about
I chose https://www.johnlewis.com website to satisfy the requirement of my first milestone. And of course, this website contains various type of data.

## Milestone 2 - Prototype finding the indivisual page for each entry
In this milestone I explored the python OOPS concept and tried to implement project in the same. To scrape the data it requires selenium library and specific browser in my case, I used chrome. and using selenium I import the chromedriver. to download the chromedriver find the below link.
https://chromedriver.chromium.org/downloads

